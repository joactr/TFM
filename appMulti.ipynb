{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jmmol\\miniconda3\\envs\\alc\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\jmmol\\miniconda3\\envs\\alc\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import face_detection\n",
    "import os, python_speech_features\n",
    "import scipy.io.wavfile as wav\n",
    "import pandas as pd\n",
    "import torch.nn.functional as F\n",
    "from talkNet import talkNet\n",
    "from dataset import MyDataset\n",
    "from torch.utils.data import DataLoader\n",
    "import tqdm\n",
    "import torch\n",
    "import cv2\n",
    "import tools\n",
    "import subprocess\n",
    "from collections import defaultdict\n",
    "import whisper\n",
    "detector = face_detection.build_detector(\n",
    "\"DSFDDetector\", confidence_threshold=.3, nms_iou_threshold=.5) #DSFDDetector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inputVideo = \"C:/Users/jmmol/Desktop/LIP-RTVE/MP4s/speaker092/speaker092_0002.mp4\"\n",
    "inputVideo = r\"inputs/dos_personas_hablando_por_turnos.mp4\"\n",
    "videoDuration = tools.checkVideoDuration(inputVideo)\n",
    "videoFrames = int(videoDuration*25)\n",
    "#tools.splitVideo(inputVideo,2,videoDuration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nº CARAS: 3\n",
      "244\n",
      "244\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "#Carga vídeo\n",
    "res, facePos, faceFrames = tools.saveMultiFace(inputVideo,detector,50)\n",
    "# AUDIO PROCESSING\n",
    "audioPath = tools.convert_video_to_audio_ffmpeg(inputVideo)\n",
    "_,sig = wav.read(audioPath)#r\"C:\\Users\\jmmol\\Desktop\\COSAS V7\\TFM\\speaker042_0063.wav\") #\n",
    "# _,sig = wav.read(r\"C:\\Users\\jmmol\\Desktop\\COSAS V7\\TFM\\speaker000_0000.wav\") \n",
    "# audioPath = r\"C:\\Users\\jmmol\\Desktop\\COSAS V7\\TFM\\speaker000_0000.wav\"\n",
    "audio = python_speech_features.mfcc(sig, 16000, numcep = 13, winlen = 0.025, winstep = 0.010) #ASUME VIDEO A 25 Y AUDIO A 100, MODIFICAR\n",
    "print(\"Nº CARAS:\",len(res))\n",
    "for cara in res.keys():\n",
    "    print(len(res[cara]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[24, 45, 46]\n"
     ]
    }
   ],
   "source": [
    "print(faceFrames[2])\n",
    "# cv2.imshow(\"My Video\", res[3][50])\n",
    "# cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "06-16 10:30:17 Model para number = 15.01\n"
     ]
    }
   ],
   "source": [
    "model = talkNet()\n",
    "#model.load_state_dict(torch.load(\"./exps/exp2/model/model_0002.model\"))\n",
    "model.load_state_dict(torch.load(\"./exps/exp1/model/model21_0006.model\"))\n",
    "windowSize = 21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 100\n"
     ]
    }
   ],
   "source": [
    "videoDir = \"C:/Users/jmmol/Desktop/COSAS V7/TFM/npz\"\n",
    "audioDir = \"C:/Users/jmmol/Desktop/COSAS V7/TFM/mfccs\"\n",
    "datasetTrain = MyDataset(51,videoDir,audioDir,\"testSamples.csv\")\n",
    "item = datasetTrain.__getitem__(4309)\n",
    "valLoader = DataLoader(dataset=datasetTrain,shuffle=False,batch_size=32,num_workers=14) #Cambiar num_workers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 16.1682,  -1.0144,   0.7126, -13.8878,  -1.9008, -15.4209,  -7.3984,\n",
      "         10.0662, -12.3333,  -1.0726,  -5.4619, -14.3538,  -9.1944]) tensor([ 16.0407,   5.1092,  -7.4174,  26.3697, -21.4168, -34.9214, -26.8578,\n",
      "        -27.1986, -11.6547,  -2.2427, -25.6342, -12.2112,   4.5576])\n",
      "Audios iguales? tensor(0) 2652\n",
      "Videos iguales? tensor(3866) 639744\n",
      "[ 18.97219561  -0.06125094 -18.13477886 -21.8923113  -25.36991588\n",
      "   0.57649002  -3.81110727  -7.30372566  12.85849014  21.97313694\n",
      "   9.50819258 -22.2504338  -30.71788893] tensor([ 11.6267,   6.2778,   2.7260,  -5.3083,  -9.2899,  -7.2238,  -8.3037,\n",
      "         -3.4917,  -6.4616, -10.6301, -17.5955,  -8.8042,  -3.2956])\n"
     ]
    }
   ],
   "source": [
    "# correctFrames, totalFrames = 0, 0\n",
    "# correctSamples, totalSamples = 0, 0\n",
    "# totalPreds = []\n",
    "# for num, (audioFeature, visualFeature, labels) in enumerate(tqdm.tqdm(valLoader)):\n",
    "#     with torch.no_grad():    \n",
    "#         output = model((audioFeature,visualFeature))\n",
    "#         labels = labels.cuda()\n",
    "#         batchPreds = torch.reshape(output[1], labels.shape)\n",
    "#         #Precision a nivel de video\n",
    "#         videoPreds = torch.mode(batchPreds,dim=1)[0]\n",
    "#         totalPreds.extend(videoPreds.detach().cpu().numpy().astype(int))\n",
    "#         labelMode = torch.mode(labels,dim=1)[0]\n",
    "#         correctSamples += (videoPreds == labelMode).sum().float()\n",
    "#         totalSamples += len(labels)\n",
    "#         # Precision a nivel de frame\n",
    "#         labels = labels.reshape((-1))\n",
    "#         correctFrames += (output[1] == labels).sum().float()\n",
    "#         totalFrames += len(labels) \n",
    "# #7865\n",
    "# print(\"Frame acc:\", correctFrames/totalFrames)\n",
    "# print(\"Sample acc:\", correctSamples/totalSamples)\n",
    "center = 47\n",
    "iAudio = tools.padAudio(audio,1,center,51,len(res[0]))\n",
    "iVideo = tools.padVideo(res[0],center,51)\n",
    "print(iAudio[40],item[0][40])\n",
    "print(\"Audios iguales?\",(iAudio == item[0]).sum(),iAudio.shape[0]*iAudio.shape[1])\n",
    "print(\"Videos iguales?\",(iVideo == item[1]).sum(),iVideo.shape[0]*112*112)\n",
    "print(audio[0],item[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sidewindow: 10\n",
      "SPEAKER 0\n",
      "SPEAKER 1\n",
      "SPEAKER 2\n",
      "244\n",
      "244\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "predArray = defaultdict(list)\n",
    "# MEDIA FRAMES\n",
    "# for actualSpeaker in res.keys():\n",
    "#     print(\"SPEAKER\", actualSpeaker)\n",
    "#     for i in range(len(res[actualSpeaker])):\n",
    "#         #center = i\n",
    "#         center = faceFrames[actualSpeaker][i]\n",
    "#         print(\"FRAME Nº \",center)\n",
    "#         iAudio = tools.padAudio(audio,1,center,windowSize,videoFrames).unsqueeze(0)\n",
    "#         iVideo = tools.padVideo(res[actualSpeaker],center-faceFrames[actualSpeaker][0],windowSize).unsqueeze(0)\n",
    "#         #print(\"audio shape: \", audio.shape)\n",
    "#         #print(\"video shape: \", video.shape)\n",
    "#         # iAudio = item[0].unsqueeze(0)\n",
    "#         # iVideo = item[1].unsqueeze(0)\n",
    "#         print(iAudio[0][0][0:5],iVideo[0][0][0][0:5])\n",
    "#         output = model((iAudio,iVideo))\n",
    "#         #output = model((audio,video))\n",
    "#         #print(output)\n",
    "#         print(\"Pred ->\",torch.mode(output[1])[0],\"\\tProb Pos ->\",torch.mean(output[1]))\n",
    "#         predArray[actualSpeaker].append(torch.mean(output[1]).detach().cpu().numpy())\n",
    "\n",
    "# SECUENCIAL\n",
    "sideWindowSize = int((windowSize-1)/2)\n",
    "print(\"sidewindow:\",sideWindowSize)\n",
    "for actualSpeaker in res.keys():\n",
    "    print(\"SPEAKER\", actualSpeaker)\n",
    "    for i in range(0,len(res[actualSpeaker])+windowSize,windowSize):\n",
    "        #center = i\n",
    "        center = faceFrames[actualSpeaker][0]+i\n",
    "        #print(\"FRAME Nº \",center)\n",
    "        iAudio = tools.padAudio(audio,1,center,windowSize,videoFrames).unsqueeze(0)\n",
    "        iVideo = tools.padVideo(res[actualSpeaker],center-faceFrames[actualSpeaker][0],windowSize).unsqueeze(0)\n",
    "        #print(iAudio[0][0][0:5],iVideo[0][0][0][0:5])\n",
    "        output = model((iAudio,iVideo))\n",
    "        predArray[actualSpeaker].extend(output[1].detach().cpu().numpy().tolist())\n",
    "    # Delete < 0 frame predictions (initial)\n",
    "    predArray[actualSpeaker] = predArray[actualSpeaker][sideWindowSize:len(res[actualSpeaker])+sideWindowSize]\n",
    "for actualSpeaker in res.keys():\n",
    "    print(len(predArray[actualSpeaker]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createVideo(videoName,imgFrames,audioPath,width,height):\n",
    "    video = cv2.VideoWriter(\"output.mp4\", 0, 25, (width,height))\n",
    "\n",
    "    for image in imgFrames:\n",
    "        video.write(image)\n",
    "\n",
    "    cv2.destroyAllWindows()\n",
    "    video.release()\n",
    "    print(' '.join([\"ffmpeg\",\"-y\",\"-i\",os.getcwd()+\"/output.mp4\",\"-i\",audioPath,\"-map\",\"0:v\",\"-map\",\"1:a\", \"-c:v\", \"copy\", \"-shortest\", os.getcwd()+\"/output2.mp4\"]))\n",
    "    res = subprocess.check_output([\"ffmpeg\",\"-y\",\"-i\",os.getcwd()+f\"/output.mp4\",\"-i\",audioPath,\"-map\",\"0:v\",\"-map\",\"1:a\", \"-c:v\", \"copy\", \"-shortest\", os.getcwd()+f\"/outputs/videos/{videoName}\"])\n",
    "    os.remove(os.getcwd()+f\"/output.mp4\")\n",
    "    \n",
    "    print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0\n",
      "0 1\n",
      "0 2\n",
      "0 3\n",
      "0 4\n",
      "0 5\n",
      "0 6\n",
      "0 7\n",
      "0 8\n",
      "0 9\n",
      "0 10\n",
      "0 11\n",
      "0 12\n",
      "0 13\n",
      "0 14\n",
      "0 15\n",
      "0 16\n",
      "0 17\n",
      "0 18\n",
      "0 19\n",
      "0 20\n",
      "0 21\n",
      "0 22\n",
      "0 23\n",
      "0 24\n",
      "0 25\n",
      "0 26\n",
      "0 27\n",
      "0 28\n",
      "0 29\n",
      "0 30\n",
      "0 31\n",
      "0 32\n",
      "0 33\n",
      "0 34\n",
      "0 35\n",
      "0 36\n",
      "0 37\n",
      "0 38\n",
      "0 39\n",
      "0 40\n",
      "0 41\n",
      "0 42\n",
      "0 43\n",
      "0 44\n",
      "0 45\n",
      "0 46\n",
      "0 47\n",
      "0 48\n",
      "0 49\n",
      "0 50\n",
      "0 51\n",
      "0 52\n",
      "0 53\n",
      "0 54\n",
      "0 55\n",
      "0 56\n",
      "0 57\n",
      "0 58\n",
      "0 59\n",
      "0 60\n",
      "0 61\n",
      "0 62\n",
      "0 63\n",
      "0 64\n",
      "0 65\n",
      "0 66\n",
      "0 67\n",
      "0 68\n",
      "0 69\n",
      "0 70\n",
      "0 71\n",
      "0 72\n",
      "0 73\n",
      "0 74\n",
      "0 75\n",
      "0 76\n",
      "0 77\n",
      "0 78\n",
      "0 79\n",
      "0 80\n",
      "0 81\n",
      "0 82\n",
      "0 83\n",
      "0 84\n",
      "0 85\n",
      "0 86\n",
      "0 87\n",
      "0 88\n",
      "0 89\n",
      "0 90\n",
      "0 91\n",
      "0 92\n",
      "0 93\n",
      "0 94\n",
      "0 95\n",
      "0 96\n",
      "0 97\n",
      "0 98\n",
      "0 99\n",
      "0 100\n",
      "0 101\n",
      "0 102\n",
      "0 103\n",
      "0 104\n",
      "0 105\n",
      "0 106\n",
      "0 107\n",
      "0 108\n",
      "0 109\n",
      "0 110\n",
      "0 111\n",
      "0 112\n",
      "0 113\n",
      "0 114\n",
      "0 115\n",
      "0 116\n",
      "0 117\n",
      "0 118\n",
      "0 119\n",
      "0 120\n",
      "0 121\n",
      "0 122\n",
      "0 123\n",
      "0 124\n",
      "0 125\n",
      "0 126\n",
      "0 127\n",
      "0 128\n",
      "0 129\n",
      "0 130\n",
      "0 131\n",
      "0 132\n",
      "0 133\n",
      "0 134\n",
      "0 135\n",
      "0 136\n",
      "0 137\n",
      "0 138\n",
      "0 139\n",
      "0 140\n",
      "0 141\n",
      "0 142\n",
      "0 143\n",
      "0 144\n",
      "0 145\n",
      "0 146\n",
      "0 147\n",
      "0 148\n",
      "0 149\n",
      "0 150\n",
      "0 151\n",
      "0 152\n",
      "0 153\n",
      "0 154\n",
      "0 155\n",
      "0 156\n",
      "0 157\n",
      "0 158\n",
      "0 159\n",
      "0 160\n",
      "0 161\n",
      "0 162\n",
      "0 163\n",
      "0 164\n",
      "0 165\n",
      "0 166\n",
      "0 167\n",
      "0 168\n",
      "0 169\n",
      "0 170\n",
      "0 171\n",
      "0 172\n",
      "0 173\n",
      "0 174\n",
      "0 175\n",
      "0 176\n",
      "0 177\n",
      "0 178\n",
      "0 179\n",
      "0 180\n",
      "0 181\n",
      "0 182\n",
      "0 183\n",
      "0 184\n",
      "0 185\n",
      "0 186\n",
      "0 187\n",
      "0 188\n",
      "0 189\n",
      "0 190\n",
      "0 191\n",
      "0 192\n",
      "0 193\n",
      "0 194\n",
      "0 195\n",
      "0 196\n",
      "0 197\n",
      "0 198\n",
      "0 199\n",
      "0 200\n",
      "0 201\n",
      "0 202\n",
      "0 203\n",
      "0 204\n",
      "0 205\n",
      "0 206\n",
      "0 207\n",
      "0 208\n",
      "0 209\n",
      "0 210\n",
      "0 211\n",
      "0 212\n",
      "0 213\n",
      "0 214\n",
      "0 215\n",
      "0 216\n",
      "0 217\n",
      "0 218\n",
      "0 219\n",
      "0 220\n",
      "0 221\n",
      "0 222\n",
      "0 223\n",
      "0 224\n",
      "0 225\n",
      "0 226\n",
      "0 227\n",
      "0 228\n",
      "0 229\n",
      "0 230\n",
      "0 231\n",
      "0 232\n",
      "0 233\n",
      "0 234\n",
      "0 235\n",
      "0 236\n",
      "0 237\n",
      "0 238\n",
      "0 239\n",
      "0 240\n",
      "0 241\n",
      "0 242\n",
      "0 243\n",
      "1 0\n",
      "1 1\n",
      "1 2\n",
      "1 3\n",
      "1 4\n",
      "1 5\n",
      "1 6\n",
      "1 7\n",
      "1 8\n",
      "1 9\n",
      "1 10\n",
      "1 11\n",
      "1 12\n",
      "1 13\n",
      "1 14\n",
      "1 15\n",
      "1 16\n",
      "1 17\n",
      "1 18\n",
      "1 19\n",
      "1 20\n",
      "1 21\n",
      "1 22\n",
      "1 23\n",
      "1 24\n",
      "1 25\n",
      "1 26\n",
      "1 27\n",
      "1 28\n",
      "1 29\n",
      "1 30\n",
      "1 31\n",
      "1 32\n",
      "1 33\n",
      "1 34\n",
      "1 35\n",
      "1 36\n",
      "1 37\n",
      "1 38\n",
      "1 39\n",
      "1 40\n",
      "1 41\n",
      "1 42\n",
      "1 43\n",
      "1 44\n",
      "1 45\n",
      "1 46\n",
      "1 47\n",
      "1 48\n",
      "1 49\n",
      "1 50\n",
      "1 51\n",
      "1 52\n",
      "1 53\n",
      "1 54\n",
      "1 55\n",
      "1 56\n",
      "1 57\n",
      "1 58\n",
      "1 59\n",
      "1 60\n",
      "1 61\n",
      "1 62\n",
      "1 63\n",
      "1 64\n",
      "1 65\n",
      "1 66\n",
      "1 67\n",
      "1 68\n",
      "1 69\n",
      "1 70\n",
      "1 71\n",
      "1 72\n",
      "1 73\n",
      "1 74\n",
      "1 75\n",
      "1 76\n",
      "1 77\n",
      "1 78\n",
      "1 79\n",
      "1 80\n",
      "1 81\n",
      "1 82\n",
      "1 83\n",
      "1 84\n",
      "1 85\n",
      "1 86\n",
      "1 87\n",
      "1 88\n",
      "1 89\n",
      "1 90\n",
      "1 91\n",
      "1 92\n",
      "1 93\n",
      "1 94\n",
      "1 95\n",
      "1 96\n",
      "1 97\n",
      "1 98\n",
      "1 99\n",
      "1 100\n",
      "1 101\n",
      "1 102\n",
      "1 103\n",
      "1 104\n",
      "1 105\n",
      "1 106\n",
      "1 107\n",
      "1 108\n",
      "1 109\n",
      "1 110\n",
      "1 111\n",
      "1 112\n",
      "1 113\n",
      "1 114\n",
      "1 115\n",
      "1 116\n",
      "1 117\n",
      "1 118\n",
      "1 119\n",
      "1 120\n",
      "1 121\n",
      "1 122\n",
      "1 123\n",
      "1 124\n",
      "1 125\n",
      "1 126\n",
      "1 127\n",
      "1 128\n",
      "1 129\n",
      "1 130\n",
      "1 131\n",
      "1 132\n",
      "1 133\n",
      "1 134\n",
      "1 135\n",
      "1 136\n",
      "1 137\n",
      "1 138\n",
      "1 139\n",
      "1 140\n",
      "1 141\n",
      "1 142\n",
      "1 143\n",
      "1 144\n",
      "1 145\n",
      "1 146\n",
      "1 147\n",
      "1 148\n",
      "1 149\n",
      "1 150\n",
      "1 151\n",
      "1 152\n",
      "1 153\n",
      "1 154\n",
      "1 155\n",
      "1 156\n",
      "1 157\n",
      "1 158\n",
      "1 159\n",
      "1 160\n",
      "1 161\n",
      "1 162\n",
      "1 163\n",
      "1 164\n",
      "1 165\n",
      "1 166\n",
      "1 167\n",
      "1 168\n",
      "1 169\n",
      "1 170\n",
      "1 171\n",
      "1 172\n",
      "1 173\n",
      "1 174\n",
      "1 175\n",
      "1 176\n",
      "1 177\n",
      "1 178\n",
      "1 179\n",
      "1 180\n",
      "1 181\n",
      "1 182\n",
      "1 183\n",
      "1 184\n",
      "1 185\n",
      "1 186\n",
      "1 187\n",
      "1 188\n",
      "1 189\n",
      "1 190\n",
      "1 191\n",
      "1 192\n",
      "1 193\n",
      "1 194\n",
      "1 195\n",
      "1 196\n",
      "1 197\n",
      "1 198\n",
      "1 199\n",
      "1 200\n",
      "1 201\n",
      "1 202\n",
      "1 203\n",
      "1 204\n",
      "1 205\n",
      "1 206\n",
      "1 207\n",
      "1 208\n",
      "1 209\n",
      "1 210\n",
      "1 211\n",
      "1 212\n",
      "1 213\n",
      "1 214\n",
      "1 215\n",
      "1 216\n",
      "1 217\n",
      "1 218\n",
      "1 219\n",
      "1 220\n",
      "1 221\n",
      "1 222\n",
      "1 223\n",
      "1 224\n",
      "1 225\n",
      "1 226\n",
      "1 227\n",
      "1 228\n",
      "1 229\n",
      "1 230\n",
      "1 231\n",
      "1 232\n",
      "1 233\n",
      "1 234\n",
      "1 235\n",
      "1 236\n",
      "1 237\n",
      "1 238\n",
      "1 239\n",
      "1 240\n",
      "1 241\n",
      "1 242\n",
      "1 243\n",
      "2 0\n",
      "2 1\n",
      "2 2\n",
      "245\n",
      "ffmpeg -y -i c:\\Users\\jmmol\\Desktop\\COSAS V7\\TFM/output.mp4 -i c:\\Users\\jmmol\\Desktop\\COSAS V7\\TFM/dos_personas_hablando_por_turnos.wav -map 0:v -map 1:a -c:v copy -shortest c:\\Users\\jmmol\\Desktop\\COSAS V7\\TFM/output2.mp4\n",
      "b''\n"
     ]
    }
   ],
   "source": [
    "#Asignación de bounding boxes y probabilidades al video de output\n",
    "os.makedirs(\"outputs/videos\", exist_ok=True)\n",
    "cap = cv2.VideoCapture(inputVideo)\n",
    "videoImages = []\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "while True:\n",
    "    ret, image = cap.read()\n",
    "    videoImages.append(image)\n",
    "    if ret == False:\n",
    "        break\n",
    "\n",
    "\n",
    "for speakerN in predArray.keys():\n",
    "    for i, fr in enumerate(faceFrames[speakerN]): #Para cada frame en el que aparezca la cara\n",
    "        try:\n",
    "            image = videoImages[fr]\n",
    "            greenValue = int(255*predArray[speakerN][i])\n",
    "            redValue = 255-greenValue\n",
    "            color = (0,greenValue,redValue)\n",
    "            #print(color)\n",
    "            print(speakerN,i)\n",
    "            xmin,ymin,xmax,ymax = facePos[speakerN][i]\n",
    "            image = cv2.rectangle(image, (xmin,ymin), (xmax,ymax),color , 1)\n",
    "            cv2.putText(image, str(predArray[speakerN][i]), (xmin, ymin-5), cv2.FONT_HERSHEY_SIMPLEX, 0.35, color, 1)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        # cv2.imshow(\"My Video\", image)\n",
    "        # cv2.waitKey(0)\n",
    "\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "print(len(videoImages))\n",
    "path = os.path.normpath(inputVideo)\n",
    "videoName = str(path.split(os.sep)[-1])\n",
    "createVideo(videoName,videoImages,audioPath,width,height)\n",
    "#print(predArray[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:00.000 --> 00:05.280]  Hace 25 años la ONU declaró el 3 de diciembre como Día Internacional de las Personas con\n",
      "[00:05.280 --> 00:09.440]  Discapacidad, con el objetivo de concienciarnos a todos sobre su situación y, en su caso,\n",
      "[00:09.440 --> 00:09.440]  el 3 de diciembre.\n"
     ]
    }
   ],
   "source": [
    "# GUARDAR DATOS \n",
    "# COGER SOLO FRAGMENTO DE AUDIO EN EL QUE SE DETECTA HABLANTE\n",
    "model = whisper.load_model(\"small\")\n",
    "transcription = model.transcribe(audioPath, language=\"es\", verbose=True)\n",
    "os.makedirs(\"outputs/npz\", exist_ok=True)\n",
    "np.savez_compressed(r\"outputs/npz/\"+videoName,facePos=facePos,faceFrames=faceFrames,preds=predArray,transcription=transcription)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#createVideo(res[3],audioPath,112,112)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:00.000 --> 00:05.280]  Hace 25 años la ONU declaró el 3 de diciembre como Día Internacional de las Personas con\n",
      "[00:05.280 --> 00:09.440]  Discapacidad, con el objetivo de concienciarnos a todos sobre su situación y, en su caso,\n",
      "[00:09.440 --> 00:09.440]  el 3 de diciembre.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded = np.load(r\"C:\\Users\\jmmol\\Desktop\\COSAS V7\\TFM\\outputs\\npz\\speaker270_0002.mp4.npz\",allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array({'text': ' Hace 25 años la ONU declaró el 3 de diciembre como Día Internacional de las Personas con Discapacidad, con el objetivo de concienciarnos a todos sobre su situación y, en su caso,', 'segments': [{'id': 0, 'seek': 0, 'start': 0.0, 'end': 5.28, 'text': ' Hace 25 años la ONU declaró el 3 de diciembre como Día Internacional de las Personas con', 'tokens': [50364, 389, 617, 3552, 11424, 635, 9299, 52, 16694, 812, 806, 805, 368, 14285, 49772, 2617, 413, 2686, 4844, 13608, 368, 2439, 8443, 296, 416, 50628], 'temperature': 0.0, 'avg_logprob': -0.5163383796566823, 'compression_ratio': 1.3311258278145695, 'no_speech_prob': 0.09169353544712067}, {'id': 1, 'seek': 0, 'start': 5.28, 'end': 9.44, 'text': ' Discapacidad, con el objetivo de concienciarnos a todos sobre su situación y, en su caso,', 'tokens': [50628, 4208, 9485, 326, 4580, 11, 416, 806, 29809, 368, 416, 537, 30322, 24979, 257, 6321, 5473, 459, 29343, 288, 11, 465, 459, 9666, 11, 50836], 'temperature': 0.0, 'avg_logprob': -0.5163383796566823, 'compression_ratio': 1.3311258278145695, 'no_speech_prob': 0.09169353544712067}, {'id': 2, 'seek': 0, 'start': 9.44, 'end': 9.44, 'text': '', 'tokens': [], 'temperature': 0.0, 'avg_logprob': -0.5163383796566823, 'compression_ratio': 1.3311258278145695, 'no_speech_prob': 0.09169353544712067, 'words': []}], 'language': 'es'},\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded[\"transcription\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "alc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
