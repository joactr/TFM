{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jmmol\\miniconda3\\envs\\alc\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\jmmol\\miniconda3\\envs\\alc\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import face_detection\n",
    "import os, python_speech_features\n",
    "import scipy.io.wavfile as wav\n",
    "import pandas as pd\n",
    "import torch.nn.functional as F\n",
    "from talkNet import talkNet\n",
    "from dataset import MyDataset\n",
    "from torch.utils.data import DataLoader\n",
    "import tqdm\n",
    "import torch\n",
    "import cv2\n",
    "import tools\n",
    "import subprocess\n",
    "from collections import defaultdict\n",
    "import whisper\n",
    "detector = face_detection.build_detector(\n",
    "\"DSFDDetector\", confidence_threshold=.3, nms_iou_threshold=.5) #DSFDDetector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inputVideo = \"C:/Users/jmmol/Desktop/LIP-RTVE/MP4s/speaker092/speaker092_0002.mp4\"\n",
    "inputVideo = r\"inputs/dos_personas_hablando_por_turnos.mp4\"\n",
    "videoDuration = tools.checkVideoDuration(inputVideo)\n",
    "videoFrames = int(videoDuration*25)\n",
    "fps = 25\n",
    "#tools.splitVideo(inputVideo,2,videoDuration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nº CARAS: 3\n",
      "244\n",
      "244\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "#Carga vídeo\n",
    "res, facePos, faceFrames = tools.saveMultiFace(inputVideo,detector,50)\n",
    "# AUDIO PROCESSING\n",
    "audioPath = tools.convert_video_to_audio_ffmpeg(inputVideo)\n",
    "_,sig = wav.read(audioPath)#r\"C:\\Users\\jmmol\\Desktop\\COSAS V7\\TFM\\speaker042_0063.wav\") #\n",
    "# _,sig = wav.read(r\"C:\\Users\\jmmol\\Desktop\\COSAS V7\\TFM\\speaker000_0000.wav\") \n",
    "# audioPath = r\"C:\\Users\\jmmol\\Desktop\\COSAS V7\\TFM\\speaker000_0000.wav\"\n",
    "audio = python_speech_features.mfcc(sig, 16000, numcep = 13, winlen = 0.025, winstep = 0.010) #ASUME VIDEO A 25 Y AUDIO A 100, MODIFICAR\n",
    "print(\"Nº CARAS:\",len(res))\n",
    "for cara in res.keys():\n",
    "    print(len(res[cara]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[24, 45, 46]\n"
     ]
    }
   ],
   "source": [
    "print(faceFrames[2])\n",
    "# cv2.imshow(\"My Video\", res[3][50])\n",
    "# cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "06-17 10:11:35 Model para number = 15.01\n"
     ]
    }
   ],
   "source": [
    "model = talkNet()\n",
    "#model.load_state_dict(torch.load(\"./exps/exp2/model/model_0002.model\"))\n",
    "model.load_state_dict(torch.load(\"./exps/exp1/model/model21_0006.model\"))\n",
    "windowSize = 21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 100\n"
     ]
    }
   ],
   "source": [
    "videoDir = \"C:/Users/jmmol/Desktop/COSAS V7/TFM/npz\"\n",
    "audioDir = \"C:/Users/jmmol/Desktop/COSAS V7/TFM/mfccs\"\n",
    "datasetTrain = MyDataset(51,videoDir,audioDir,\"testSamples.csv\")\n",
    "item = datasetTrain.__getitem__(4309)\n",
    "valLoader = DataLoader(dataset=datasetTrain,shuffle=False,batch_size=32,num_workers=14) #Cambiar num_workers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jmmol\\Desktop\\COSAS V7\\TFM\\tools.py:182: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\utils\\tensor_new.cpp:248.)\n",
      "  video = torch.FloatTensor(video)\n"
     ]
    }
   ],
   "source": [
    "# correctFrames, totalFrames = 0, 0\n",
    "# correctSamples, totalSamples = 0, 0\n",
    "# totalPreds = []\n",
    "# for num, (audioFeature, visualFeature, labels) in enumerate(tqdm.tqdm(valLoader)):\n",
    "#     with torch.no_grad():    \n",
    "#         output = model((audioFeature,visualFeature))\n",
    "#         labels = labels.cuda()\n",
    "#         batchPreds = torch.reshape(output[1], labels.shape)\n",
    "#         #Precision a nivel de video\n",
    "#         videoPreds = torch.mode(batchPreds,dim=1)[0]\n",
    "#         totalPreds.extend(videoPreds.detach().cpu().numpy().astype(int))\n",
    "#         labelMode = torch.mode(labels,dim=1)[0]\n",
    "#         correctSamples += (videoPreds == labelMode).sum().float()\n",
    "#         totalSamples += len(labels)\n",
    "#         # Precision a nivel de frame\n",
    "#         labels = labels.reshape((-1))\n",
    "#         correctFrames += (output[1] == labels).sum().float()\n",
    "#         totalFrames += len(labels) \n",
    "# #7865\n",
    "# print(\"Frame acc:\", correctFrames/totalFrames)\n",
    "# print(\"Sample acc:\", correctSamples/totalSamples)\n",
    "center = 47\n",
    "iAudio = tools.padAudio(audio,1,center,51,len(res[0])).unsqueeze(0)\n",
    "iVideo = tools.padVideo(res[0],center,51).unsqueeze(0)\n",
    "# print(iAudio[40],item[0][40])\n",
    "# print(\"Audios iguales?\",(iAudio == item[0]).sum(),iAudio.shape[0]*iAudio.shape[1])\n",
    "# print(\"Videos iguales?\",(iVideo == item[1]).sum(),iVideo.shape[0]*112*112)\n",
    "# print(audio[0],item[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sidewindow: 10\n",
      "SPEAKER 0\n",
      "[0.00575357535853982, 0.004212664731312543, 0.0037662821006961165, 0.002758789421059191, 0.0031045403233729302, 0.0035456935175694525, 0.004341259452402592, 0.004440342498529702, 0.004939847215346247, 0.005239380619086921, 0.005512945291000574, 0.005961367773812228, 0.007106480810671882, 0.01177507221230488, 0.014857717078708815, 0.015459113801185176, 0.013772441407083887, 0.014352512714952886, 0.015490671161359566, 0.041090964840598244, 0.10894690007821586, 0.22351751527692992, 0.27905774782570597, 0.27317377025282086, 0.20902657760156812, 0.17705058921847608, 0.17368036830911535, 0.17926561870965035, 0.1820821679895762, 0.15575969062536776, 0.12423155708103628, 0.1293954389200192, 0.14793126160312706, 0.19632464894347354, 0.1864345880808472, 0.16434953758778842, 0.1321820748831492, 0.13466173977557677, 0.147777790627401, 0.1370731265367189, 0.10134230076593813, 0.0670497513900873, 0.047765249242841055, 0.039339255020425026, 0.036371279002401065, 0.03008969033093813, 0.029239745146927926, 0.04138125335181024, 0.0494167237990976, 0.04974326875089223, 0.03787010466092312, 0.03505637280158619, 0.033508115434737806, 0.02896503110611757, 0.019012135698981088, 0.0182730657226702, 0.01764244179850281, 0.01920337501087599, 0.01625411297151302, 0.01677405272064143, 0.023188481270087536, 0.03945632654034855, 0.04962577711837498, 0.05740589433690065, 0.05306549857075445, 0.06577560434499499, 0.0628914025818796, 0.06369915953023042, 0.056062681426004, 0.0575800384495305, 0.055564308413020805, 0.04705009448816712, 0.04243370408933468, 0.0377501385478406, 0.03765288804631113, 0.03489042544929776, 0.033224517805833166, 0.028720334807861743, 0.024921438662864257, 0.026093808876173973, 0.029528563645552553, 0.03622985328113402, 0.08299956145402285, 0.13904495113569867, 0.1873542368332443, 0.2321364871118016, 0.22187981737401968, 0.21849082389927377, 0.1739611088478632, 0.16949679071088064, 0.15014095595840632, 0.13876786402015578, 0.12680608394247833, 0.13982854770352687, 0.13912763068920928, 0.13980154316937288, 0.12683570830258115, 0.11857489659299006, 0.11504067602185793, 0.10867461023000466, 0.11108129984079991, 0.10092237735431749, 0.09100936186428973, 0.07268569539339834, 0.0668901058583808, 0.06684027526943885, 0.06262434038452809, 0.06062530662040215, 0.05613456606537661, 0.06237481733181251, 0.06097916094400233, 0.058593754774244465, 0.0505099640459397, 0.04527037852465504, 0.04301108414960937, 0.04497732645967092, 0.04475693860994085, 0.04413115185706772, 0.05190933652034454, 0.06057658664290112, 0.06418675786100836, 0.05496988465934398, 0.04858583559869213, 0.050999517730529874, 0.052496643164642774, 0.04904979031096775, 0.04395953802406726, 0.04301114712943795, 0.05365955347404897, 0.05279510438318289, 0.0697411981412992, 0.07778572383874156, 0.08955076379626145, 0.08115007159392565, 0.07178135632540719, 0.08171993836034629, 0.0781047620144193, 0.07701272094634441, 0.059602278673756746, 0.054766057222680506, 0.05395799159878589, 0.0641430747684513, 0.06419753477303354, 0.05950763713239613, 0.04174534174054295, 0.03549648899966163, 0.02771877054648223, 0.024643209965845556, 0.026570240494526793, 0.0374297610876437, 0.042579281783633426, 0.05680772208219381, 0.09126423575222276, 0.13707175517238257, 0.17914632249255352, 0.18614617576705705, 0.17837822015859023, 0.17261382374422674, 0.15655105960177235, 0.1655690338910893, 0.1459754170354597, 0.1387354588126673, 0.14591233863417158, 0.16871357955562907, 0.24948218749366538, 0.32014137463655107, 0.35095823157486994, 0.3056898287048811, 0.23688999376647954, 0.25639577810577957, 0.297120293312402, 0.404026725168875, 0.48625417920132125, 0.5484439019357458, 0.535821160102154, 0.487999286020556, 0.457353839514459, 0.4960052380964287, 0.49227083528803145, 0.5057683187818878, 0.4836400743042029, 0.4886112192036897, 0.5045403415854134, 0.44209941930885216, 0.46331941178693115, 0.40369180798246235, 0.38756975243681174, 0.3323965950209047, 0.3367279550317426, 0.321368078674508, 0.3178519315270549, 0.31785519638864784, 0.39096528050638885, 0.45263216192830846, 0.507528406486207, 0.5126383394118917, 0.48018489303528683, 0.45561474943857816, 0.4028174666703559, 0.37125295056126434, 0.29765882002240435, 0.26295000922709294, 0.2613123079517595, 0.2715915249105706, 0.2940152491469289, 0.2770607950618966, 0.3003605442776324, 0.3209191028250286, 0.30471641523653414, 0.2607295450424044, 0.29125551297577823, 0.2851551210539768, 0.282485815427472, 0.2115247082923835, 0.19308332368995118, 0.17213508156421825, 0.12184006508737485, 0.08888677473670785, 0.0787814530280356, 0.08881945474202987, 0.11513146914785466, 0.1302079493224639, 0.16053709884871153, 0.14466571329949157, 0.12694413442275318, 0.09275988364771852, 0.07996259464009055, 0.07088101634430746, 0.06198030710166953, 0.25330361421703124, 0.4805324488793713, 0.7443517701525446, 0.8410250320159168, 0.9097990876599497, 0.9427914075113757, 0.9644062029962097, 0.9786577494879918, 0.986602659614577, 0.9913395807714721, 0.9939538145361027, 0.9949228896671363, 0.9956916220639449, 0.9957337455278263, 0.9962719981666392, 0.9960087494278275, 0.9952844313983185, 0.9941470124011911, 0.9933784729220418, 0.9940514728161419, 0.9949383793415759, 0.797136932708941, 0.5592013584555111, 0.2730781421933252, 0.16805842674420973, 0.08954045314604239, 0.05314808216015179, 0.03030125860377426, 0.0186144478830426, 0.011268252116703124, 0.007490284238713192, 0.005122360548346309, 0.003920109634123996, 0.0035051678870229573, 0.003230232681010389, 0.004466126727180697, 0.004729714521972584, 0.004827676360696607, 0.0038290593901720246, 0.0032730738604485415, 0.0028682483845972225, 0.0024772716312049356, 0.002379458784590456, 0.0024135715251578705]\n",
      "SPEAKER 1\n",
      "[0.00804783139998714, 0.006410582000777746, 0.004608097542465354, 0.0036905971720504263, 0.0054407853352992485, 0.0074800840223363295, 0.009999595737407604, 0.010815689755261565, 0.013053905146565164, 0.013750659556692194, 0.0161422344289723, 0.016954205839486054, 0.017903744828284072, 0.017519987659699008, 0.017534752401436683, 0.019909629325026594, 0.024934352325932115, 0.028823870169617783, 0.030238740123318432, 0.18932687843332785, 0.40591188068626477, 0.6593053845563099, 0.757920445750999, 0.8112285003166804, 0.8166811442893721, 0.8177048413281319, 0.8283250535497398, 0.8600324641325873, 0.9017319531366852, 0.9283427854733552, 0.9480669639802478, 0.9562062701116678, 0.9489047333166436, 0.9454501009999934, 0.9331378845688633, 0.9166662622558306, 0.8955382910844516, 0.8792394903608971, 0.8853956126130749, 0.882199564978797, 0.8734993349911833, 0.8075209817380756, 0.780616902758541, 0.7422013083217476, 0.7632395989421319, 0.7543942126798877, 0.7838000448523275, 0.8050353444645119, 0.8051292719246472, 0.771748394545532, 0.7602395798676748, 0.7681957263485533, 0.7902449521352743, 0.7981295929683414, 0.7765932659161698, 0.7833088343577739, 0.7861356672662451, 0.8022462773771111, 0.8032132980320646, 0.7876577028740409, 0.8080665518085709, 0.8413158476024769, 0.8968726132096936, 0.9386987001389662, 0.9604442645007867, 0.9694887010173975, 0.9750327375891104, 0.9779158615128054, 0.9809953389648228, 0.9818656842140253, 0.9794809027177399, 0.9801946680523992, 0.9806577365485897, 0.9825644175542614, 0.9839978234215835, 0.9857972204005219, 0.9892725458852402, 0.9908665190225332, 0.992328176522204, 0.9919706675673521, 0.9916003384094335, 0.990182426197646, 0.971675461612822, 0.9526399558198451, 0.9330740381526711, 0.910160469902749, 0.9088771042859498, 0.8732033526215532, 0.8822416514744266, 0.8212361217718023, 0.822653788959396, 0.8017489804334407, 0.8176016108167387, 0.8108961182729241, 0.786398627238831, 0.8056776280536144, 0.8062094238223135, 0.8219172744384485, 0.799106196070762, 0.7563284981942493, 0.7264119963595635, 0.7296672886499899, 0.7560007176128727, 0.7737009411497283, 0.7539446609570796, 0.7592083244084831, 0.7516806420865403, 0.7454408471930476, 0.6576438856588045, 0.601888068072293, 0.5392134505110816, 0.5704624254131471, 0.6144881470247505, 0.6874090516938478, 0.7152261199080568, 0.7078306703944471, 0.6918882149597623, 0.6744206795557357, 0.6673649483443228, 0.6443867004510749, 0.6460598081373755, 0.6542365766886984, 0.6685723341971179, 0.7071867921907435, 0.7661430958197171, 0.8461599799443162, 0.9047924871391958, 0.9068572014092562, 0.9121224539412273, 0.8960031578233316, 0.9071973436320562, 0.9047710097339792, 0.9035450392912185, 0.8876226896138469, 0.8723859415062634, 0.8710370775004197, 0.8895114132076172, 0.8974846280465452, 0.8968158075245141, 0.8911869284685819, 0.8882091535371203, 0.9004396249933645, 0.907889758414532, 0.9212820132324826, 0.9318689336064414, 0.7660685043420928, 0.5582876052075524, 0.3116492503682859, 0.2298746507746773, 0.16564854036138227, 0.14952929479716964, 0.13328770689806246, 0.1267885974158439, 0.11641817789025473, 0.10705721201865534, 0.10619807555897243, 0.10096196112432454, 0.09695366092924591, 0.10069805849751372, 0.11149404453747443, 0.12888050968780818, 0.152960387672678, 0.16308761373341926, 0.16336672259519575, 0.14997833567526125, 0.1562518951313024, 0.14937018278803316, 0.13690869648005394, 0.09890498481653474, 0.08456717362246548, 0.1009880323066393, 0.09846435510870304, 0.1661573205635891, 0.1660399885301112, 0.17784459564726082, 0.10968311031537, 0.0841999011954015, 0.07191794932301879, 0.0678262340975195, 0.06885885417449462, 0.06247909888528166, 0.06076298081853064, 0.06273221735930531, 0.08059821042170953, 0.08527793939416989, 0.07831847661387167, 0.07982976476183856, 0.08071856296754394, 0.08826237139409351, 0.09077442599138039, 0.13333277430158055, 0.1872486460980209, 0.20788005275286342, 0.20148814354443836, 0.19437772217762747, 0.20221227569873443, 0.1940280831791313, 0.18789968000425664, 0.18662382756858525, 0.1801881332233811, 0.1571030839990419, 0.13977031089357744, 0.13330447609146562, 0.12424174023153849, 0.10052308665196616, 0.08803197428378062, 0.07765309122457727, 0.07341210403451764, 0.05736199492596401, 0.03964259467083664, 0.025229287514470546, 0.018169393223517544, 0.01641086407281477, 0.01518107681418828, 0.014739468550628205, 0.011010614401678144, 0.008817940631389753, 0.007318602893220391, 0.0074111983044390164, 0.007891894896539336, 0.006863211413186135, 0.006397449274047937, 0.0056180244300059615, 0.006605672212543873, 0.0070683163272206, 0.008167712464191356, 0.0077069027060656225, 0.0070806700267288455, 0.007249830443159379, 0.1166288919212987, 0.19036916332438641, 0.34066588502450934, 0.3517381037440284, 0.4102986845830838, 0.3950430965150623, 0.4491013528741397, 0.44171618536238333, 0.4123928309152413, 0.35637802128359347, 0.34680113663487344, 0.3904215648066548, 0.3982865095399383, 0.38758208422967017, 0.33932894045459, 0.3135922941435476, 0.3197293649177507, 0.3433797332233162, 0.3398106106648192, 0.3126774903360072, 0.31430488595867967, 0.2580598054618596, 0.20731333075260502, 0.09406021435177321, 0.06133404486360426, 0.032123486316585584, 0.019831177428542436, 0.011725264701992354, 0.00798201271932402, 0.005588956271193597, 0.004471642011278463, 0.0037772985455305904, 0.0037734022325902673, 0.0036508004602003306, 0.004410540487822646, 0.005291215597356871, 0.006957860435341252, 0.006747246112984412, 0.006205002423993041, 0.004524988721869048, 0.004134750555169174, 0.0034540357062018403, 0.003516980377545267, 0.003140325355311221]\n",
      "SPEAKER 2\n",
      "[0.020157330359021824, 0.02358091219017903, 0.02551919824133317, 0.022863026360670727, 0.02016731837640206, 0.01605782561848561, 0.013551428110847872, 0.011263398939112823, 0.009058703232345979, 0.00803766787109832, 0.006372876361458222, 0.006056394297461573, 0.005988584318812606, 0.00824663989422456, 0.01105196068278616, 0.015963369716742438, 0.018262000035336703, 0.01929135377419589, 0.018598122264587298, 0.015415075907909751, 0.012479188096860508, 0.00825713466138012, 0.006792245483302697, 0.005472622650977431, 0.005389788911048588, 0.005591907930308675, 0.008606978076892716, 0.009127396672990265, 0.009350379443064126, 0.008171837503149338, 0.007764904142236515, 0.006584250376174853, 0.00441098815676884, 0.00344868856066429, 0.0032378238373672553, 0.0030818535980695868, 0.0052437577818739405, 0.005575626930038579, 0.006614019279391814, 0.005441272948836624, 0.005824341663623002, 0.005713508334775595]\n",
      "244\n",
      "244\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "totalScores = defaultdict(list)\n",
    "meanWSize = 5\n",
    "meanSideSize = int((meanWSize-1)/2)\n",
    "# MEDIA FRAMES\n",
    "# for actualSpeaker in res.keys():\n",
    "#     print(\"SPEAKER\", actualSpeaker)\n",
    "#     for i in range(len(res[actualSpeaker])):\n",
    "#         #center = i\n",
    "#         center = faceFrames[actualSpeaker][i]\n",
    "#         print(\"FRAME Nº \",center)\n",
    "#         iAudio = tools.padAudio(audio,1,center,windowSize,videoFrames).unsqueeze(0)\n",
    "#         iVideo = tools.padVideo(res[actualSpeaker],center-faceFrames[actualSpeaker][0],windowSize).unsqueeze(0)\n",
    "#         #print(\"audio shape: \", audio.shape)\n",
    "#         #print(\"video shape: \", video.shape)\n",
    "#         # iAudio = item[0].unsqueeze(0)\n",
    "#         # iVideo = item[1].unsqueeze(0)\n",
    "#         print(iAudio[0][0][0:5],iVideo[0][0][0][0:5])\n",
    "#         scores,labels= model((iAudio,iVideo))\n",
    "#         #print(output)\n",
    "#         print(\"Pred ->\",torch.mode(labels)[0],\"\\tProb Pos ->\",torch.mean(scores))\n",
    "#         predArray[actualSpeaker].append(torch.mean(labels).detach().cpu().numpy())\n",
    "\n",
    "\n",
    "# SECUENCIAL\n",
    "sideWindowSize = int((windowSize-1)/2)\n",
    "print(\"sidewindow:\",sideWindowSize)\n",
    "for actualSpeaker in res.keys():\n",
    "    print(\"SPEAKER\", actualSpeaker)\n",
    "    for i in range(0,len(res[actualSpeaker])+windowSize,windowSize):\n",
    "        #center = i\n",
    "        center = faceFrames[actualSpeaker][0]+i\n",
    "        #print(\"FRAME Nº \",center)\n",
    "        iAudio = tools.padAudio(audio,1,center,windowSize,videoFrames).unsqueeze(0)\n",
    "        iVideo = tools.padVideo(res[actualSpeaker],center-faceFrames[actualSpeaker][0],windowSize).unsqueeze(0)\n",
    "        #print(iAudio[0][0][0:5],iVideo[0][0][0][0:5])\n",
    "        scores,labels= model((iAudio,iVideo))\n",
    "        totalScores[actualSpeaker].extend(scores[:,1].detach().cpu().numpy().tolist())\n",
    "        #predArray[actualSpeaker].extend(labels.detach().cpu().numpy().tolist())\n",
    "\n",
    "    # MEAN SLIDING WINDOW\n",
    "    for i in range(len(totalScores[actualSpeaker])):\n",
    "        ini = max(0,i-meanSideSize) # No negative values\n",
    "        end = i+meanSideSize+1 # +1 as python does not take into account last value\n",
    "        #print(ini,end)\n",
    "        totalScores[actualSpeaker][i] = np.mean(totalScores[actualSpeaker][ini:end])\n",
    "    print(totalScores[actualSpeaker])\n",
    "\n",
    "predArray = defaultdict(list)\n",
    "thr = 0.5\n",
    "# APPLY THRESHOLD\n",
    "for actualSpeaker in res.keys():\n",
    "    # Delete < 0 frame predictions (initial)\n",
    "    totalScores[actualSpeaker] = totalScores[actualSpeaker][sideWindowSize:len(res[actualSpeaker])+sideWindowSize]\n",
    "    # Classify as speaking if score higher than threshold\n",
    "    for sc in totalScores[actualSpeaker]:\n",
    "        predLabel = 1 if sc > thr else 0\n",
    "        predArray[actualSpeaker].append(predLabel)\n",
    "\n",
    "    print(len(predArray[actualSpeaker]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createVideo(videoName,imgFrames,audioPath,width,height):\n",
    "    video = cv2.VideoWriter(\"output.mp4\", 0, 25, (width,height))\n",
    "\n",
    "    for image in imgFrames:\n",
    "        video.write(image)\n",
    "\n",
    "    cv2.destroyAllWindows()\n",
    "    video.release()\n",
    "    print(' '.join([\"ffmpeg\",\"-y\",\"-i\",os.getcwd()+\"/output.mp4\",\"-i\",audioPath,\"-map\",\"0:v\",\"-map\",\"1:a\", \"-c:v\", \"copy\", \"-shortest\", os.getcwd()+\"/output2.mp4\"]))\n",
    "    res = subprocess.check_output([\"ffmpeg\",\"-y\",\"-i\",os.getcwd()+f\"/output.mp4\",\"-i\",audioPath,\"-map\",\"0:v\",\"-map\",\"1:a\", \"-c:v\", \"copy\", \"-shortest\", os.getcwd()+f\"/outputs/videos/{videoName}\"])\n",
    "    os.remove(os.getcwd()+f\"/output.mp4\")\n",
    "    \n",
    "    print(res)\n",
    "\n",
    "# Returns a list of [start,end] timestamps in seconds of the parts where a speaker is speaking with minimum length of minLength frames\n",
    "def getSpeaking(arr,minLength,fps):\n",
    "    prev_idx = 0\n",
    "    posFrames = 0\n",
    "    idx_list = []\n",
    "    for i,num in enumerate(arr):\n",
    "        if num == 1:\n",
    "            posFrames +=1\n",
    "        else:\n",
    "            if i-prev_idx >= minLength:\n",
    "                idx_list.append((prev_idx/fps,i/fps))\n",
    "            prev_idx = i\n",
    "            posFrames = 0\n",
    "    return idx_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "245\n",
      "ffmpeg -y -i c:\\Users\\jmmol\\Desktop\\COSAS V7\\TFM/output.mp4 -i c:\\Users\\jmmol\\Desktop\\COSAS V7\\TFM/dos_personas_hablando_por_turnos.wav -map 0:v -map 1:a -c:v copy -shortest c:\\Users\\jmmol\\Desktop\\COSAS V7\\TFM/output2.mp4\n",
      "b''\n"
     ]
    }
   ],
   "source": [
    "#Asignación de bounding boxes y probabilidades al video de output\n",
    "os.makedirs(\"outputs/videos\", exist_ok=True)\n",
    "cap = cv2.VideoCapture(inputVideo)\n",
    "videoImages = []\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "while True:\n",
    "    ret, image = cap.read()\n",
    "    videoImages.append(image)\n",
    "    if ret == False:\n",
    "        break\n",
    "\n",
    "\n",
    "for speakerN in totalScores.keys():\n",
    "    for i, fr in enumerate(faceFrames[speakerN]): #Para cada frame en el que aparezca la cara\n",
    "        try:\n",
    "            image = videoImages[fr]\n",
    "            greenValue = int(255*predArray[speakerN][i])\n",
    "            redValue = 255-greenValue\n",
    "            color = (0,greenValue,redValue)\n",
    "            #print(color)\n",
    "            xmin,ymin,xmax,ymax = facePos[speakerN][i]\n",
    "            image = cv2.rectangle(image, (xmin,ymin), (xmax,ymax),color , 1)\n",
    "            cv2.putText(image, \"{:.2f}\".format(totalScores[speakerN][i]*100), (xmin, ymin-5), cv2.FONT_HERSHEY_SIMPLEX, 0.35, color, 1)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        # cv2.imshow(\"My Video\", image)\n",
    "        # cv2.waitKey(0)\n",
    "\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "path = os.path.normpath(inputVideo)\n",
    "videoName = str(path.split(os.sep)[-1])\n",
    "createVideo(videoName,videoImages,audioPath,width,height)\n",
    "#print(predArray[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jmmol\\miniconda3\\envs\\alc\\lib\\site-packages\\whisper\\timing.py:42: UserWarning: Failed to launch Triton kernels, likely due to missing CUDA toolkit; falling back to a slower median kernel implementation...\n",
      "  warnings.warn(\n",
      "c:\\Users\\jmmol\\miniconda3\\envs\\alc\\lib\\site-packages\\whisper\\timing.py:146: UserWarning: Failed to launch Triton kernels, likely due to missing CUDA toolkit; falling back to a slower DTW implementation...\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:00.320 --> 00:05.500]  y la población civil de guta oriental en siria sigue sufriendo los efectos de la guerra.\n"
     ]
    }
   ],
   "source": [
    "# GUARDAR DATOS \n",
    "# COGER SOLO FRAGMENTO DE AUDIO EN EL QUE SE DETECTA HABLANTE\n",
    "os.makedirs(\"outputs/npz\", exist_ok=True)\n",
    "transcription = model.transcribe(audioPath, language=\"es\", verbose=True,word_timestamps=True)\n",
    "np.savez_compressed(r\"outputs/npz/\"+videoName,facePos=facePos,faceFrames=faceFrames,preds=predArray,transcription=transcription)\n",
    "model = whisper.load_model(\"small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' y', ' la', ' población', ' civil', ' de', ' guta', ' oriental', ' en', ' siria', ' sigue', ' sufriendo', ' los', ' efectos', ' de', ' la', ' guerra.']\n",
      "[(0.32, 0.84), (0.84, 0.94), (0.94, 1.2), (1.2, 1.62), (1.62, 1.86), (1.86, 2.1), (2.1, 2.56), (2.56, 2.66), (2.66, 3.14), (3.14, 3.54), (3.54, 4.22), (4.22, 4.48), (4.48, 5.04), (5.04, 5.1), (5.1, 5.24), (5.24, 5.5)]\n"
     ]
    }
   ],
   "source": [
    "# EXTRAER PARTE APROPIADA DE LA TRANSCRIPCIÓN\n",
    "wordArr = []\n",
    "alignArr = []\n",
    "for seg in transcription[\"segments\"]:\n",
    "    for w in seg[\"words\"]:\n",
    "        wordArr.append(w[\"word\"])\n",
    "        alignArr.append((w[\"start\"],w[\"end\"]))\n",
    "print(wordArr)\n",
    "print(alignArr)\n",
    "pdRows = []\n",
    "\n",
    "for speakerN in totalScores.keys():\n",
    "    for (ini,end) in getSpeaking(predArray[speakerN],5,25):\n",
    "        iniW, endW = -1, -1\n",
    "        for i, (alignIni, alignEnd) in enumerate(alignArr):\n",
    "            if iniW == -1 and ini <= alignEnd and ini >= alignIni:\n",
    "                iniW = i\n",
    "            if endW == -1 and end <= alignEnd and end >= alignIni:\n",
    "                endW = i\n",
    "        if iniW > -1 and endW > -1:\n",
    "            newRow = {'video':inputVideo, 'speaker':speakerN, 'ini': ini, 'end':end, 'npzPath': r\"outputs/npz/\"+videoName, 'transcription':''.join(wordArr[iniW:endW+1])}\n",
    "            pdRows.append(newRow)\n",
    "\n",
    "df = pd.DataFrame(pdRows,columns=['video', 'speaker', 'ini', 'end', 'npzPath', 'transcription'])\n",
    "df.to_csv(r\"outputs/res.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded = np.load(r\"C:\\Users\\jmmol\\Desktop\\COSAS V7\\TFM\\outputs\\npz\\speaker270_0002.mp4.npz\",allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array({'text': ' Hace 25 años la ONU declaró el 3 de diciembre como Día Internacional de las Personas con Discapacidad, con el objetivo de concienciarnos a todos sobre su situación y, en su caso,', 'segments': [{'id': 0, 'seek': 0, 'start': 0.0, 'end': 5.28, 'text': ' Hace 25 años la ONU declaró el 3 de diciembre como Día Internacional de las Personas con', 'tokens': [50364, 389, 617, 3552, 11424, 635, 9299, 52, 16694, 812, 806, 805, 368, 14285, 49772, 2617, 413, 2686, 4844, 13608, 368, 2439, 8443, 296, 416, 50628], 'temperature': 0.0, 'avg_logprob': -0.5163383796566823, 'compression_ratio': 1.3311258278145695, 'no_speech_prob': 0.09169353544712067}, {'id': 1, 'seek': 0, 'start': 5.28, 'end': 9.44, 'text': ' Discapacidad, con el objetivo de concienciarnos a todos sobre su situación y, en su caso,', 'tokens': [50628, 4208, 9485, 326, 4580, 11, 416, 806, 29809, 368, 416, 537, 30322, 24979, 257, 6321, 5473, 459, 29343, 288, 11, 465, 459, 9666, 11, 50836], 'temperature': 0.0, 'avg_logprob': -0.5163383796566823, 'compression_ratio': 1.3311258278145695, 'no_speech_prob': 0.09169353544712067}, {'id': 2, 'seek': 0, 'start': 9.44, 'end': 9.44, 'text': '', 'tokens': [], 'temperature': 0.0, 'avg_logprob': -0.5163383796566823, 'compression_ratio': 1.3311258278145695, 'no_speech_prob': 0.09169353544712067, 'words': []}], 'language': 'es'},\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded[\"transcription\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "alc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
