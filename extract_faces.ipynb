{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jmmol\\miniconda3\\envs\\alc\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\jmmol\\miniconda3\\envs\\alc\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import face_detection\n",
    "from collections import defaultdict\n",
    "import os, python_speech_features\n",
    "import scipy.io.wavfile as wav\n",
    "import random\n",
    "import pandas as pd\n",
    "import pickle\n",
    "detector = face_detection.build_detector(\n",
    "  \"DSFDDetector\", confidence_threshold=.2, nms_iou_threshold=.2)\n",
    "pathVideo = \"C:/Users/jmmol/Desktop/LIP-RTVE/MP4s\"\n",
    "pathMFCC = \"C:/Users/jmmol/Desktop/COSAS V7/TFM/mfccs\"\n",
    "pathAudio = \"C:/Users/jmmol/Desktop/LIP-RTVE/WAVs\"\n",
    "pathFaces = \"C:/Users/jmmol/Desktop/COSAS V7/TFM/npz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createFolders(path):\n",
    "    \"\"\"\n",
    "    Crea una carpeta por cada hablante y dentro una por cada vídeo de ese hablante\n",
    "    También crea un diccionario que incluye los hablantes y cada uno de los nombres de sus vídeos y lo devuelve\n",
    "    Ej: speaker000/001\n",
    "    \"\"\"\n",
    "    speakerDict = defaultdict(list)\n",
    "    for (root,dirs,files) in os.walk(path, topdown=True):\n",
    "        #print (dirs)\n",
    "        for speaker in dirs:\n",
    "            os.makedirs(\"imgs/\"+speaker, exist_ok=True)\n",
    "            os.makedirs(\"mfccs/\"+speaker, exist_ok=True)\n",
    "            os.makedirs(\"npz/\"+speaker, exist_ok=True)\n",
    "        #print (files)\n",
    "        for f in files:\n",
    "            speaker, nmuestra = f.split(\"_\")\n",
    "            os.makedirs(\"imgs/\"+speaker+\"/\"+nmuestra.split(\".\")[0], exist_ok=True)\n",
    "            speakerDict[speaker].append(f[:-4]) #Quitamos .mp4\n",
    "    print ('Directorios creados')\n",
    "    return speakerDict\n",
    "\n",
    "def extractBiggestFace(img):\n",
    "    \"\"\"\n",
    "    Detecta todas las caras de una imagen y devuelve la más grande recortada y reescalada a 112x112\n",
    "    \"\"\"\n",
    "    detections = detector.detect(img)\n",
    "    idx_max = -1\n",
    "    area_max = -1\n",
    "    for i,cntr in enumerate(detections):\n",
    "        xmin,ymin,xmax,ymax = int(cntr[0]),int(cntr[1]),int(cntr[2]),int(cntr[3]) #Guardamos bounding box\n",
    "        area = (xmax-xmin)*(ymax-ymin)\n",
    "        if area > area_max: #Comprobamos si la cara es la más grande\n",
    "            idx_max = i\n",
    "            area_max = area\n",
    "            #print(area,idx_max)\n",
    "        #cv2.rectangle(img, (xmin, ymin), (xmax, ymax), (0, 0, 255), 2)\n",
    "\n",
    "    cntr = detections[idx_max]\n",
    "    try:\n",
    "        xmin,ymin,xmax,ymax = int(cntr[0]),int(cntr[1]),int(cntr[2]),int(cntr[3])\n",
    "        return cv2.resize(img[max(ymin,0):ymax, xmin:xmax], (112, 112)) #Cara detectada, reescalamos\n",
    "    except:\n",
    "        print(cntr)\n",
    "        cv2.imshow('image',img)\n",
    "        cv2.waitKey(0)\n",
    "\n",
    "def saveFaceCrops(videoPath):\n",
    "    speaker, videoID = videoPath.split(\"/\")[-2:]\n",
    "    videoID = videoID.split(\"_\")[1]\n",
    "    print(speaker, videoID)\n",
    "    vidcap = cv2.VideoCapture(videoPath)\n",
    "    success,image = vidcap.read()\n",
    "    count = 0\n",
    "    facesCount = 0\n",
    "    while success:\n",
    "        cv2.imwrite(\"imgs/\"+speaker+\"/\"+videoID+\"/\"+str(count)+'.jpg', extractBiggestFace(image)) #Detectamos y guardamos cara\n",
    "        success,image = vidcap.read()\n",
    "        count += 1\n",
    "    return count+1 #Devuelve número de frames\n",
    "\n",
    "def convertToNPZ(speakerDict, lengthsFilename):\n",
    "    \"\"\"\n",
    "    Convierte caras recortadas en npz en su directorio y devuelve longitudes de video\n",
    "    \"\"\"\n",
    "    videoLength = defaultdict(list)\n",
    "    for speaker in speakerDict:\n",
    "        for sample in speakerDict[speaker]:\n",
    "            folder = \"C:/Users/jmmol/Desktop/COSAS V7/TFM/imgs/\"+speaker+\"/\"+sample.split(\"_\")[1]\n",
    "            images = []\n",
    "            #numFrames = len(os.listdir(folder))\n",
    "            for filename in sorted(os.listdir(folder),key=lambda x: int(x)):\n",
    "                img = cv2.imread(os.path.join(folder,filename))\n",
    "                if img is not None:\n",
    "                    images.append(img)\n",
    "            numFrames = len(images)\n",
    "            videoLength[\"videos\"].append(sample)\n",
    "            videoLength[\"lengths\"].append(numFrames)\n",
    "            np.savez_compressed(r\"C:/Users/jmmol/Desktop/COSAS V7/TFM/npz/\"+speaker+\"/\"+sample,images=images)\n",
    "    with open(lengthsFilename, 'wb') as f:\n",
    "        pickle.dump(videoLength, f)\n",
    "\n",
    "def extractMFCC(speakerDict,pathMFCC,pathAudio,pathNPZ):\n",
    "    for speaker in speakerDict:\n",
    "        for sample in speakerDict[speaker]:\n",
    "            _,sig = wav.read(pathAudio+\"/\"+speaker+\"/\"+sample+\".wav\")\n",
    "            videoRec = np.load(pathNPZ+\"/\"+speaker+\"/\"+sample+\".npz\")[\"images\"]\n",
    "            maxAudio = len(videoRec)*4 #Video a 25hz, audio a 100hz\n",
    "            audio = python_speech_features.mfcc(sig, 16000, numcep = 13, winlen = 0.025, winstep = 0.010)\n",
    "            if audio.shape[0] < maxAudio: #Si es un poco más corto hacemos padding\n",
    "                shortage = maxAudio - audio.shape[0]\n",
    "                audio = np.pad(audio, ((0, shortage), (0,0)), 'wrap')\n",
    "            audio = audio[:maxAudio,:] #Se recorta\n",
    "            np.savez_compressed(pathMFCC+\"/\"+speaker+\"/\"+sample,mfcc=audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directorios creados\n"
     ]
    }
   ],
   "source": [
    "speakerDict = createFolders(pathVideo)\n",
    "#for speaker in sorted(list(speakerDict.keys())):\n",
    "#    for video in speakerDict[speaker]:\n",
    "#        saveFaceCrops(pathVideo+\"/\"+speaker+\"/\"+video)\n",
    "#convertToNPZ(speakerDict,\"lengths.pickle\")\n",
    "#extractMFCC(speakerDict,pathMFCC,pathAudio,pathFaces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29 116\n"
     ]
    }
   ],
   "source": [
    "fotos = np.load(r\"C:\\Users\\jmmol\\Desktop\\COSAS V7\\TFM\\npz\\speaker334\\speaker334_0000.npz\")[\"images\"]\n",
    "audio = np.load(r\"C:\\Users\\jmmol\\Desktop\\COSAS V7\\TFM\\mfccs\\speaker334\\speaker334_0000.npz\")[\"mfcc\"]\n",
    "print(len(fotos),len(audio))\n",
    "#cv2.imshow(\"test\",fotos[-1])\n",
    "#cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createSamples(splitSpeakers,nSamples,videoLengths,filename):\n",
    "    n = 0\n",
    "    sampleLabels = [\"positive\",\"partialMismatchSameSample\",\"partialMismatchDiffSample\",\"completeMismatch\"]\n",
    "    speakers = list(splitSpeakers.keys())\n",
    "    sampleList = []\n",
    "    while n < nSamples: #TIENE QUE SER DISTINTOS VIDEOS\n",
    "        sType = np.random.choice(sampleLabels,p=[0.5,0.166666666,0.166666666,0.166666666])\n",
    "        speakerVideo = random.choice(speakers)\n",
    "        videoSample = random.choice(splitSpeakers[speakerVideo])\n",
    "        videoLength = videoLengths[videoSample]\n",
    "        center = random.randint(0,videoLength)\n",
    "        if sType == \"positive\":\n",
    "            audioSample = videoSample #AUDIO SAMPLE\n",
    "            #audioCenter = random.randint(0,videoLength*4)\n",
    "            sampleLabel = 1\n",
    "        if sType == \"partialMismatchSameSample\":\n",
    "            videoSample\n",
    "            #audioCenter = random.randint(0,videoLengths[audioSample]*4)\n",
    "            sampleLabel = 0\n",
    "        if sType == \"partialMismatchDiffSample\":\n",
    "            speakerAudio = speakerVideo\n",
    "            audioSample = random.choice([s for s in splitSpeakers[speakerVideo] if s != videoSample])\n",
    "            #audioCenter = random.randint(0,videoLengths[audioSample]*4)\n",
    "            sampleLabel = 0   \n",
    "        if sType == \"completeMismatch\":\n",
    "            speakerAudio = random.choice([s for s in speakers if s != speakerVideo])\n",
    "            audioSample = random.choice(splitSpeakers[speakerAudio])\n",
    "            #audioCenter = random.randint(0,videoLengths[audioSample]*4)\n",
    "            sampleLabel = 0\n",
    "\n",
    "        newRow = {'video':videoSample, 'audio':audioSample, 'label': sampleLabel, 'center': center}\n",
    "        if newRow not in sampleList:\n",
    "            sampleList.append(newRow)\n",
    "            n+=1\n",
    "    df = pd.DataFrame(sampleList,columns=['video', 'audio', 'label', 'center'])\n",
    "    df.to_csv(filename)\n",
    "    return df\n",
    "\n",
    "\n",
    "def splitToDict(speakerList,lengths):\n",
    "    speakerDict = defaultdict(list)\n",
    "    for speaker in speakerList:\n",
    "        speakerDict[speaker[:-5]].append(speaker)\n",
    "    return speakerDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'trainSamples.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m trainDF \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(\u001b[39m\"\u001b[39m\u001b[39mC:/Users/jmmol/Desktop/LIP-RTVE/SPLITS/speaker-independent/train.csv\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      5\u001b[0m trainSpeakers \u001b[39m=\u001b[39m splitToDict(trainDF[\u001b[39m\"\u001b[39m\u001b[39msampleID\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mvalues\u001b[39m.\u001b[39mtolist(),lengths)\n\u001b[1;32m----> 6\u001b[0m df \u001b[39m=\u001b[39m createSamples(trainSpeakers,\u001b[39m100000\u001b[39;49m,lengths,\u001b[39m'\u001b[39;49m\u001b[39mtrainSamples.csv\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "Cell \u001b[1;32mIn[4], line 36\u001b[0m, in \u001b[0;36mcreateSamples\u001b[1;34m(splitSpeakers, nSamples, videoLengths, filename)\u001b[0m\n\u001b[0;32m     34\u001b[0m         n\u001b[39m+\u001b[39m\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m\n\u001b[0;32m     35\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(sampleList,columns\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mvideo\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39maudio\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mlabel\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mcenter\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m---> 36\u001b[0m df\u001b[39m.\u001b[39;49mto_csv(filename)\n",
      "File \u001b[1;32mc:\\Users\\jmmol\\miniconda3\\envs\\alc\\lib\\site-packages\\pandas\\core\\generic.py:3772\u001b[0m, in \u001b[0;36mNDFrame.to_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[0;32m   3761\u001b[0m df \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m, ABCDataFrame) \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mto_frame()\n\u001b[0;32m   3763\u001b[0m formatter \u001b[39m=\u001b[39m DataFrameFormatter(\n\u001b[0;32m   3764\u001b[0m     frame\u001b[39m=\u001b[39mdf,\n\u001b[0;32m   3765\u001b[0m     header\u001b[39m=\u001b[39mheader,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3769\u001b[0m     decimal\u001b[39m=\u001b[39mdecimal,\n\u001b[0;32m   3770\u001b[0m )\n\u001b[1;32m-> 3772\u001b[0m \u001b[39mreturn\u001b[39;00m DataFrameRenderer(formatter)\u001b[39m.\u001b[39;49mto_csv(\n\u001b[0;32m   3773\u001b[0m     path_or_buf,\n\u001b[0;32m   3774\u001b[0m     lineterminator\u001b[39m=\u001b[39;49mlineterminator,\n\u001b[0;32m   3775\u001b[0m     sep\u001b[39m=\u001b[39;49msep,\n\u001b[0;32m   3776\u001b[0m     encoding\u001b[39m=\u001b[39;49mencoding,\n\u001b[0;32m   3777\u001b[0m     errors\u001b[39m=\u001b[39;49merrors,\n\u001b[0;32m   3778\u001b[0m     compression\u001b[39m=\u001b[39;49mcompression,\n\u001b[0;32m   3779\u001b[0m     quoting\u001b[39m=\u001b[39;49mquoting,\n\u001b[0;32m   3780\u001b[0m     columns\u001b[39m=\u001b[39;49mcolumns,\n\u001b[0;32m   3781\u001b[0m     index_label\u001b[39m=\u001b[39;49mindex_label,\n\u001b[0;32m   3782\u001b[0m     mode\u001b[39m=\u001b[39;49mmode,\n\u001b[0;32m   3783\u001b[0m     chunksize\u001b[39m=\u001b[39;49mchunksize,\n\u001b[0;32m   3784\u001b[0m     quotechar\u001b[39m=\u001b[39;49mquotechar,\n\u001b[0;32m   3785\u001b[0m     date_format\u001b[39m=\u001b[39;49mdate_format,\n\u001b[0;32m   3786\u001b[0m     doublequote\u001b[39m=\u001b[39;49mdoublequote,\n\u001b[0;32m   3787\u001b[0m     escapechar\u001b[39m=\u001b[39;49mescapechar,\n\u001b[0;32m   3788\u001b[0m     storage_options\u001b[39m=\u001b[39;49mstorage_options,\n\u001b[0;32m   3789\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\jmmol\\miniconda3\\envs\\alc\\lib\\site-packages\\pandas\\io\\formats\\format.py:1186\u001b[0m, in \u001b[0;36mDataFrameRenderer.to_csv\u001b[1;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[0;32m   1165\u001b[0m     created_buffer \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m   1167\u001b[0m csv_formatter \u001b[39m=\u001b[39m CSVFormatter(\n\u001b[0;32m   1168\u001b[0m     path_or_buf\u001b[39m=\u001b[39mpath_or_buf,\n\u001b[0;32m   1169\u001b[0m     lineterminator\u001b[39m=\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1184\u001b[0m     formatter\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfmt,\n\u001b[0;32m   1185\u001b[0m )\n\u001b[1;32m-> 1186\u001b[0m csv_formatter\u001b[39m.\u001b[39;49msave()\n\u001b[0;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m created_buffer:\n\u001b[0;32m   1189\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "File \u001b[1;32mc:\\Users\\jmmol\\miniconda3\\envs\\alc\\lib\\site-packages\\pandas\\io\\formats\\csvs.py:240\u001b[0m, in \u001b[0;36mCSVFormatter.save\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    236\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    237\u001b[0m \u001b[39mCreate the writer & save.\u001b[39;00m\n\u001b[0;32m    238\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    239\u001b[0m \u001b[39m# apply compression and byte/text conversion\u001b[39;00m\n\u001b[1;32m--> 240\u001b[0m \u001b[39mwith\u001b[39;00m get_handle(\n\u001b[0;32m    241\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfilepath_or_buffer,\n\u001b[0;32m    242\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmode,\n\u001b[0;32m    243\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoding,\n\u001b[0;32m    244\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49merrors,\n\u001b[0;32m    245\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompression,\n\u001b[0;32m    246\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstorage_options,\n\u001b[0;32m    247\u001b[0m ) \u001b[39mas\u001b[39;00m handles:\n\u001b[0;32m    248\u001b[0m     \u001b[39m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[0;32m    249\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwriter \u001b[39m=\u001b[39m csvlib\u001b[39m.\u001b[39mwriter(\n\u001b[0;32m    250\u001b[0m         handles\u001b[39m.\u001b[39mhandle,\n\u001b[0;32m    251\u001b[0m         lineterminator\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    256\u001b[0m         quotechar\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mquotechar,\n\u001b[0;32m    257\u001b[0m     )\n\u001b[0;32m    259\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_save()\n",
      "File \u001b[1;32mc:\\Users\\jmmol\\miniconda3\\envs\\alc\\lib\\site-packages\\pandas\\io\\common.py:859\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    854\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[0;32m    855\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    856\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    857\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[0;32m    858\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[1;32m--> 859\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\n\u001b[0;32m    860\u001b[0m             handle,\n\u001b[0;32m    861\u001b[0m             ioargs\u001b[39m.\u001b[39;49mmode,\n\u001b[0;32m    862\u001b[0m             encoding\u001b[39m=\u001b[39;49mioargs\u001b[39m.\u001b[39;49mencoding,\n\u001b[0;32m    863\u001b[0m             errors\u001b[39m=\u001b[39;49merrors,\n\u001b[0;32m    864\u001b[0m             newline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    865\u001b[0m         )\n\u001b[0;32m    866\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    867\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[0;32m    868\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: 'trainSamples.csv'"
     ]
    }
   ],
   "source": [
    "with open('lengths.pickle', 'rb') as f: #Diccionario con clave de videos y clave de longitudes, ambas listas se corresponden\n",
    "    lengths = pickle.load(f)\n",
    "lengths = dict(zip(lengths[\"videos\"],lengths[\"lengths\"]))\n",
    "trainDF = pd.read_csv(\"C:/Users/jmmol/Desktop/LIP-RTVE/SPLITS/speaker-independent/train.csv\")\n",
    "trainSpeakers = splitToDict(trainDF[\"sampleID\"].values.tolist(),lengths)\n",
    "df = createSamples(trainSpeakers,100000,lengths,'trainSamples.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "alc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
