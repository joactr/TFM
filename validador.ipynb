{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jmmol\\miniconda3\\envs\\alc\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\jmmol\\miniconda3\\envs\\alc\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import face_detection\n",
    "import os, python_speech_features\n",
    "import scipy.io.wavfile as wav\n",
    "import pandas as pd\n",
    "import torch.nn.functional as F\n",
    "from talkNet import talkNet\n",
    "from dataset import MyDataset\n",
    "from torch.utils.data import DataLoader\n",
    "import tqdm\n",
    "import torch\n",
    "import cv2\n",
    "import pickle\n",
    "import tools\n",
    "import sys\n",
    "import subprocess\n",
    "from collections import defaultdict\n",
    "import whisper\n",
    "module_path = os.path.abspath(os.path.join('./light'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "from light.ASD import ASD as lightASD\n",
    "detector = face_detection.build_detector(\n",
    "\"DSFDDetector\", confidence_threshold=.3, nms_iou_threshold=.5) #DSFDDetector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "09-29 15:56:05 Model para number = 15.01\n"
     ]
    }
   ],
   "source": [
    "model = talkNet()\n",
    "#model.load_state_dict(torch.load(\"./exps/exp2/model/model_0002.model\"))\n",
    "model.load_state_dict(torch.load(\"./exps/exp1/model/model51_0004.model\"))\n",
    "#model.load_state_dict(torch.load(\"./exps/exp1/model/model21_0006.model\"))\n",
    "\n",
    "windowSize = 51\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 100\n"
     ]
    }
   ],
   "source": [
    "videoDir = \"C:/Users/jmmol/Desktop/COSAS V7/TFM/npz\"\n",
    "audioDir = \"C:/Users/jmmol/Desktop/COSAS V7/TFM/mfccs\"\n",
    "datasetTrain = MyDataset(windowSize,videoDir,audioDir,\"testSamples.csv\")\n",
    "item = datasetTrain.__getitem__(0)\n",
    "valLoader = DataLoader(dataset=datasetTrain,shuffle=False,batch_size=8,num_workers=14) #Cambiar num_workers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3751/3751 [03:40<00:00, 17.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame acc: tensor(0.9324, device='cuda:0')\n",
      "Sample acc: tensor(0.9323, device='cuda:0')\n",
      "AUC: 0.9937767005133894\n"
     ]
    }
   ],
   "source": [
    "correctFrames, totalFrames = 0, 0\n",
    "correctSamples, totalSamples = 0, 0\n",
    "totalPreds = []\n",
    "totalScores = []\n",
    "for num, (audioFeature, visualFeature, labels) in enumerate(tqdm.tqdm(valLoader)):\n",
    "    with torch.no_grad():    \n",
    "        audioFeature, visualFeature, labels = audioFeature.cuda(), visualFeature.cuda(), labels.cuda()\n",
    "        predScores,predLabels = model((audioFeature,visualFeature)) #(audioFeature,visualFeature) si talknet\n",
    "        batchPreds = torch.reshape(predLabels, labels.shape)\n",
    "        #Precision a nivel de video\n",
    "        videoPreds = torch.mode(batchPreds,dim=1)[0]\n",
    "        totalPreds.extend(videoPreds.detach().cpu().numpy().astype(int))\n",
    "        for ten in torch.split(predScores[:,1],windowSize):\n",
    "            totalScores.append(torch.mean(ten).detach().cpu().numpy())\n",
    "        labelMode = torch.mode(labels,dim=1)[0]\n",
    "        correctSamples += (videoPreds == labelMode).sum().float()\n",
    "        totalSamples += len(labels)\n",
    "        # Precision a nivel de frame\n",
    "        labels = labels.reshape((-1))\n",
    "        correctFrames += (predLabels == labels).sum().float()\n",
    "        totalFrames += len(labels) \n",
    "#7865\n",
    "print(\"Frame acc:\", correctFrames/totalFrames)\n",
    "print(\"Sample acc:\", correctSamples/totalSamples)\n",
    "# center = 47\n",
    "# iAudio = tools.padAudio(audio,1,center,51,len(res[0])).unsqueeze(0)\n",
    "# iVideo = tools.padVideo(res[0],center,51).unsqueeze(0)\n",
    "# print(iAudio[40],item[0][40])\n",
    "# print(\"Audios iguales?\",(iAudio == item[0]).sum(),iAudio.shape[0]*iAudio.shape[1])\n",
    "# print(\"Videos iguales?\",(iVideo == item[1]).sum(),iVideo.shape[0]*112*112)\n",
    "# print(audio[0],item[0][0])\n",
    "\n",
    "\n",
    "from sklearn import metrics\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "df = pd.read_csv(\"testSamples.csv\")\n",
    "df2 = pd.DataFrame({'pred':totalPreds})\n",
    "df3 = pd.DataFrame({'posScore':totalScores})\n",
    "df[\"pred\"] = df2\n",
    "df[\"posScore\"] = df3\n",
    "df.to_csv(\"testPredsX.csv\")\n",
    "g_truth = pd.read_csv(\"testSamples.csv\")[\"label\"].values.tolist()\n",
    "fpr, tpr, thresholds = metrics.roc_curve(g_truth, totalScores)\n",
    "auc = metrics.roc_auc_score(g_truth, totalScores)\n",
    "np.savetxt('cli.txt', df[df[\"label\"]==1][\"posScore\"].values, fmt='%f')\n",
    "np.savetxt('imp.txt', df[df[\"label\"]==0][\"posScore\"].values, fmt='%f')\n",
    "nCorrect = 0\n",
    "for i in df[df[\"label\"]==1][\"posScore\"].values:\n",
    "    if i >=0.5:\n",
    "        nCorrect +=1\n",
    "print(\"AUC:\", auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "alc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
